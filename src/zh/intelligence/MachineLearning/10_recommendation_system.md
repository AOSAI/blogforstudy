---
title: 3-2 推荐系统
order: 10
author: AOSAI
date: 2024-08-22
category:
  - 机器学习
tag:
  - 推荐系统
---

<style>
  @media (orientation:landscape){
    .layout{
      display:flex;
    }
  }
  @media (orientation:portrait){
    .layout{}
  }
</style>

推荐系统（Recommendation System）

## 1. 推荐系统入门

如今大多数的软件都会使用推荐系统，比如：短视频类型的抖音、快手；购物平台的淘宝、京东；影视软甲的爱奇艺、优酷；音乐软件的网易云、qq 音乐……

这些软件会给你推荐，它们认为你可能会喜欢的视频/商品/音乐等等，从而提高用户的粘性，让客户愿意为它们持续消费。从事实来看，现如今确实很大一部分的销售额都是由各自的推荐系统驱动的。

所以，推荐系统为一个公司带来的经济价值是很高的。在学术界，如何提高推荐系统的性能，是一个长期热议的话题。这一章，我们就来看看推荐系统是如何工作的。

### 1.1 评分和预测

我们用一个电影推荐的应用作为例子。推荐系统要做的事情是，预测用户对某一个电影的评分。

假设我们评分的范围是 [0，6]，一分一颗星，最高五颗星。数据集如下所示：

|        Movie         | Alice(1) | Bob(2) | Carel(3) | Dave(4) |
| :------------------: | :------: | :----: | :------: | :-----: |
|     Love at last     |    5     |   5    |    0     |    0    |
|   Romance forever    |    5     |   ?    |    ?     |    0    |
| Cute puppies of love |    ?     |   4    |    0     |    ?    |
|  Nonstop car chases  |    0     |   0    |    5     |    4    |
|  Swords vs. karate   |    0     |   0    |    5     |    ?    |

- $n_{u}$ 表示用户的数量。这里 $n_{u}=4$
- $n_{m}$ 表示电影的数量。这里 $n_{m}=5$

- 如果用户 j 已经给电影 i 打分了，记为 $r(i,j)=1$。比如，Alice 已经给第一个电影打分了，但是第三个电影还没有，记为 $r(1,1)=1$，$r(3,1)=0$。
- $y^{(i,j)}$ 表示用户给电影打的分数，仅仅只在 $r(i,j)=1$ 时记录。比如，$y^{(3,2)}=4$

假设我们可以获取电影的一些信息，比如电影的类别：喜剧、爱情、动作、科幻……，并使用这些标签来训练一个学习算法。我们就可以通过用户的喜好范围，来筛选出该用户最有可能打高分的一些电影。

### 1.2 通过特征推测参数

OK，我们把刚才的设想拿过来，数据集还和 1.1 小节相同，但提取了两个特征值，x1 为爱情片的成分占比，x2 为动作片的成分占比。

|        Movie         | Alice(1) | ……  | x1(romance) | x2(action) |
| :------------------: | :------: | :-: | :---------: | :--------: |
|     Love at last     |    5     | ……  |     0.9     |     0      |
|   Romance forever    |    5     | ……  |     1.0     |    0.01    |
| Cute puppies of love |    ?     | ……  |    0.99     |     0      |
|  Nonstop car chases  |    0     | ……  |     0.1     |    1.0     |
|  Swords vs. karate   |    0     | ……  |      0      |    0.9     |

特征向量就是特征 x1 和 x2 之间的组合，比如 $x^{(1)}=[0.9,0]^{T}，x^{(3)}=[0.99,0]^{T}$

**我们可以通过简单的线性函数，来预测用户 j 对电影 i 的评分：$w^{(j)}\cdot{x^{(i)}}+b^{(j)}$**

比如我们假设 $w^{(1)}=[5,0]^{T}，b^{(1)}=0$，那么 $w^{(1)}\cdot{x^{(3)}}+b^{(1)}=4.95$

这个线性函数模型，需要被训练的参数是 w 和 b，成本函数要做的事情，就是调整 w 和 b 参数，让预测评分减去真实评分的值最小化。

**对某一个用户训练参数的成本函数公式**如下所示：

$$
J(w^{(j)},b^{(j)})=\frac{1}{2}\sum_{i:r(i,j)=1}\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2}\sum_{k=1}^{n}\left(w_{k}^{(j)}\right)^{2}
$$

如果还记的一元线性回归的内容，求和符号前的 $\frac{1}{2}$ 原本应该是 $\frac{1}{2m}$，m 表示数据集中的用例总数，在推荐系统中表示被用户 j 评过分的电影 i 的总数，是可以被省略掉的。

公式后方的求和模块，是正则化，在逻辑回归章节有记录。n 表示特征总数。

**对所有用户训练参数的成本函数公式**如下所示：

$$
J\begin{pmatrix}
w^{(1)}, ..., w^{(n_{u})} \\
b^{(1)}, ..., b^{(n_{u})}
\end{pmatrix}=\frac{1}{2}\sum_{j=1}^{n_{u}}\sum_{i:r(i,j)=1}\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2}\sum_{j=1}^{n_{u}}\sum_{k=1}^{n}\left(w_{k}^{(j)}\right)^{2}
$$

### 1.3 通过参数推测特征

如果每部电影都有一些特征，例如上一节中的 x1 和 x2，它会告诉你这部电影多少成分是浪漫的，多少成分是动作的。这样我们就可以通过基本的线性回归来学习预测电影的评分。

但是，如果你没有这些特征的数据该怎么办？让我们来看看如何从数据中学习或得出这些特征。

![10.1 通过参数训练特征](/machinelearning/four/10-01.png =560x)

假设四位用户的参数为，$w^{(1)}=w^{(2)}=[5,0]^{T}$，$w^{(3)}=w^{(4)}=[0,5]^{T}$，所有的 $b^{(j)}=0$，我们可以通过线性回归方程式，将其构建成一个方程组：

$$
\begin{cases}
w^{(1)}\cdot{x^{(1)}}+b^{(1)} \approx 5 \\
w^{(2)}\cdot{x^{(1)}}+b^{(2)} \approx 5 \\
w^{(3)}\cdot{x^{(1)}}+b^{(3)} \approx 0 \\
w^{(4)}\cdot{x^{(1)}}+b^{(4)} \approx 0
\end{cases} \tag{1}
$$

通过解方程组，我们可以得到 $x^{(1)}=[1,0]^{T}$ 这样一个结果。同理，其他电影 i 的特征向量，也可以通过这种方式计算。

总结一下，我们就可以得到推算特征的成本函数。其实写法是和推算参数一样的，只不过计算的变量，以及正则化的对象发生了变化：

$$
J(x^{(i)})=\frac{1}{2}\sum_{j:r(i,j)=1}\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2}\sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}
$$

$$
J\left(x^{(1)}, ..., x^{(n_{m})}\right)=
\frac{1}{2}\sum_{i=1}^{n_{m}}\sum_{j:r(i,j)=1}\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2}\sum_{i=1}^{n_{m}}\sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}
$$

## 2. 协同过滤算法

在 1.2 小节中，我们假设存在特征，从而推导参数。
在 1.3 小节中，我们假设存在参数，从而推导特征。

如果特征和参数都不存在呢？我们将两者结合一下，便会得到协同过滤算法的思想。

$$
\begin{align}
J(w,b,x) &= \frac{1}{2}\sum_{j:r(i,j)=1}\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}-y^{(i,j)}\right)^{2}   \\
         &+ \frac{\lambda}{2}\sum_{j=1}^{n_{u}}\sum_{k=1}^{n}\left(w_{k}^{(j)}\right)^{2} \\
         &+ \frac{\lambda}{2}\sum_{i=1}^{n_{m}}\sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}
\end{align} \tag{1}
$$

$$
min\left(w^{(1)}, ..., w^{(n_{u})};b^{(1)}, ..., b^{(n_{u})};x^{(1)}, ..., x^{(n_{m})}\right)
$$

成本函数的目标就是最小化所有的参数，我们也可以通过梯度下降来完成这个步骤。但是协同过滤和原本的线性回归相比，梯度下降的方式还是有一些差别的：

![10.2 协同过滤的梯度下降](/machinelearning/four/10-02.png =560x)

我们会发现，特征向量 x 在协同过滤算法中变成了一个参数，并且它也需要随着迭代持续的更新。

协同过滤这个名字，可以理解为，因为多个用户合作评价了同一部电影，让你了解到这部电影可能是什么样的，从而猜测什么样的特征向量适合该电影，而这又反过来可以让你预测，没有看过这部电影的用户可能对这个电影有什么样的评价。

### 2.1 二进制标签（Binary labels）

推荐系统的许多重要应用都涉及二进制标签，而不是用户给你 0 到 6 星评级，他们只是以某种方式让你感觉到他们喜欢或者不喜欢这个项目。

假设我们用 1、0、？三个符号表示二进制标签：

- 1 表示给用户展示项目后，用户参与了该项目
- 0 表示给用户展示项目后，用户未参与该项目
- ？表示尚未给用户展示该项目

举个例子：

1. 用户是否在该商品展示后购买此商品。1 为购买，0 为未购买，？为没有看过此商品。

2. 在社交媒体网站，用户是否喜欢或收藏该项目。1 为喜欢/收藏，0 为不喜欢/未收藏，？为用户没有看到过这个项目。

3. 用户是否在该项目上花费了至少 30s。如果是，记为 1，说明这个项目很吸引人；如果不是，记为 0；如果尚未向用户展示该项目，记为？。

在之前的预测中，我们使用了线性回归做预测：通过 $w^{(j)}\cdot{x^{(i)}}+b^{(j)}$ 来预测 $y^{(i,j)}$。

对于二进制标签而言，我们需要预测的是 $y^{(i,j)}$ 是否等于 1。因此，我们使用逻辑回归来完成：

$$
g(z)=\frac{1}{1+e^{-z}}=\frac{1}{1+e^{w^{(j)}\cdot{x^{(i)}}+b^{(j)}}}
$$

学习模型都从线性回归变成逻辑回归了，成本函数自然也不能例外：

二进制标签的单个对象的损失函数可以写为：

$$
f_{x,b,x}(x)=g\left(w^{(j)}\cdot{x^{(i)}}+b^{(j)}\right)
$$

$$
L\left(f_{(w,b,x)}(x),y^{(i,j)}\right)=-y^{(i,j)}\log{\left(f_{(w,b,x)}(x)\right)}-(1-y^{(i,j)})\log{\left(1-f_{(w,b,x)}(x)\right)}
$$

所有对象的成本函数：

$$
J(w,b,x)=\sum_{(i,j):r(i,j)=1}L\left(f_{(w,b,x)}(x),y^{(i,j)}\right)
$$

### 2.2 均值归一化

![10.3 均值归一化1](/machinelearning/four/10-03.png =560x)

假设我们有一个新的用户叫做 Eve，他刚使用爱奇艺，还没有看过任何的视频。成本函数是为了让特征最小化，所以 w 很有可能是 $[0,0]^{T}$，b 仍旧等于 0。

这样一来，预测 Eve 用户对电影的评分，也就都等于 0，这显然是有问题的。我们可以通过均值归一化，来一定程度的改善这个问题。

![10.4 均值归一化2](/machinelearning/four/10-04.png =560x)

首先，我们将所有的评分构建为一个矩阵。计算每一行，也就是同一部电影的所有评分，的平均值，记为 μ。在这里，$\mu=[2.5, 2.5, 2, 2.25, 1.25]^{T}$

用原本的评分减去平均值，就得到了新的评分 $new\_ y^{(i,j)}$，为图中最右侧矩阵所示。此时的线性回归方程应该写成这样：$w^{(j)}\cdot{x^{(i)}}+b^{(j)}+\mu_{i}$

欸，通过新的线性回归方程，我们会发现，尚未看过任何电影的 Eve 同学，它对电影的评分预测就等于均值 μ。仔细想想，这个预测结果确实要比所有评分都为零要合理的多。

除了将矩阵的行进行均值归一，我们还可以将矩阵的列进行均值归一，这也是合理的，适用于有一部电影，所有人都没有看过的情况。但是在这个例子中，用行比用列更好。

### 2.3 TensorFlow 实现协同过滤

也许你常用 TensorFlow 去构建神经网络模型，没错，它在神经网络上的效果非常好。但同样，TensorFlow 也适用于构建其他类型的学习算法，比如协同过滤算法。

吴恩达教授喜欢使用 TensorFlow 的原因之一是：对于许多应用程序而言，为了实现梯度下降，你需要找到成本函数的导数，但 TensorFlow 有自动帮你计算成本函数的导数的功能。你需要做的仅仅是实现成本函数，无需了解任何微积分，无需自己求导，只需要短短几行代码就可以获得 TensorFlow 用于计算和优化成本函数导数项的功能。

![10.5 梯度下降简化版](/machinelearning/four/10-05.png =560x)

这张图是我们初见梯度下降时用的图，b=0 不需要被优化，只需要求 w 的偏导数就行，从图中我们知道目标值在 x=1 处，因为 x=1 处的切线斜率（也就是 w 的偏导数）等于 0。

写成公式的形式，就如下图 10.6 左上方的 J 和 w 所示：

![10.6 TensorFlow实现自动偏微分1](/machinelearning/four/10-06.png =560x)

- w = tf.Variable(3.0) 这行代码会告诉 tensorflow，该参数 w 就是我们想要优化的参数，并将其初始化为 3.0

- tf.GradientTape() 该方法记录成本 J 所需的步骤或者说操作序列

- tape.gradient( costJ, [w] ) 该方法会自动计算关于 w 的导数，也就是 $\frac{d}{d_{w}}J(w)$

这种自动计算导数/偏微分的方式叫做 Auto Diff，不管是 Tensorflow 还是 Pytouch，还是其他的机器学习包都有，有的时候也被称作 Auto Grad。

上面的代码只是一个例子，如果放到协同过滤算法中，它会变成如下这样：

![10.7 TensorFlow实现自动偏微分2](/machinelearning/four/10-07.png =560x)

cost_value 的输入有：参数 w 和 b，特征参数 x 向量，均值归一化的评分 Ynorm，R 表示用户已经打过分的项目 $r(i,j)$，用户的数量 num_users，电影的数量 num_movies，以及正则化参数 lambda。

### 2.4 寻找相关特征

如果你来到一个在线购物网站，并且你正在看一个特定的项目，比如一本特定的书，该网站可能会向你显示类似“这里有一些其他的与这本书相似的书”之类的推荐信息。

当你查看一个项目时，它会为你提供其它类似或相关的项目供你考虑，这个操作是如何做到的？其实协同过滤算法很容易做到这一点：

对于给定特征 $x^{(i)}$ 的项目 i，我们只需要类比其他的项目，它们的特征 $x^{(k)}$ 是否与 $x^{(i)}$ 相似。也就是计算两个特征之间的距离，看它们是不是足够小：

$$\sum_{l=1}^{n}\left(x_{l}^{(k)}-x_{l}^{(i)}\right)$$

我们可以取 5 个或者 10 个特征之间距离最小的项目，给用户做相似项目推荐。

### 2.5 局限性，缺点

- 冷启动问题

当你有一个新项目，很少有用户评价过；或者我们有一个新用户评价的项目很少。那么对于该项目/该用户的协同过滤效果可能不会非常准确。

即使我们已经通过均值归一化，一定程度上在解决冷启动的问题，但是效果依旧不佳。

- 没有一个自然的方式来使用**边信息**，或关于项目/用户的**附加信息**

比如目录中给定的电影：电影的类型、有没有电影明星、出自于哪个工作室、预算是多少等等。你可能有很多关于给定电影的特征。

比如某单个用户：用户的个人信息（年龄，性别，位置等等）、表达的偏好（例如喜欢动作篇，不喜欢爱情篇）、IP 地址信息（群体喜好倾向性）、是通过移动端还是 PC 端访问你的网站……

这些都是你可以获得的小提示，它们都可以与用户的偏好相关联。但是协同过滤没有办法有效的把它们全部的利用起来。

## 3. 基于内容的过滤算法

- 协同过滤算法

一般来说，协同过滤算法会根据你的评分，给出和你相似评分的用户，看看他们喜欢什么，从而推断你喜欢什么。

- 基于内容的过滤算法

它需要每个用户的一些特征，以及每个项目的一些特征，用这两者间的特征，来尝试决定哪些项目和用户可能彼此匹配。

![10.8 基于内容的过滤算法1](/machinelearning/four/10-08.png =560x)

就比如用户特征和电影特征分别有上图所示的很多种，我们通过匹配 $x_{m}^{(i)}$ 和 $x_{u}^{(j)}$，来提高推荐的性能。

观察图中特征我们知道，协同过滤中的用户打分特征还是存在的。另外需要注意的是，用户和电影的特征向量大小是可能会有差异的，但是不影响，只要在做向量乘法的时候转换成大小一致就行了。

![10.9 基于内容的过滤算法2](/machinelearning/four/10-09.png =560x)

线性回归预测中的 b 已经被消掉了，因为没有意义。 w 被转化成 $v_{u}^{(j)}$，x 转化成了 $v_{m}^{(i)}$。这两个向量是分别从用户特征和电影特征中提取计算出来的。

前者可能表示用户对不同类型电影的喜爱程度，后者可能表示电影所包含的不同类型的成分含量。这两个向量特征长度一定是一致的，因为要做向量乘法。

### 3.1 基于内容过滤的深度学习方法

为什么要用神经网络呢，我们回想一下神经网络层的样子。

![10.10 基于内容过滤的神经网络1](/machinelearning/four/10-10.png =560x)

第一层的神经元最多，第二层往后逐渐的减少，最后输出层的神经元可以缩减为我们需求的大小，比如 32 个（组成一个 32 大小的向量）。

并且神经网络输入的特征可能是很繁琐的很多的内容，但是输出的特征却是我们期望的推断后的某一个方向的内容。

这样一来，用户和电影的特征向量大小一致，并且具有相关性，就可以通过点积来计算两者间的匹配程度。

![10.11 基于内容过滤的神经网络2](/machinelearning/four/10-11.png =560x)

如果对决策树那一章节还有印象，我们说过神经网络的优点之一就是可以把多个小网络模型，结合起来变成一个大模型。就像现在，对于用户的神经网络和对于电影的神经网络，两者一结合就可以完成基于内容的过滤算法。

当然了，是学习算法就少不了成本函数。但图中的成本函数，只是一个总的成本函数，具体问题可能还需要做拆分。

基于内容的过滤算法，同样可以做到相似项目推荐。就拿这个电影的例子，我们取不同电影之间的特征向量的距离之差的平方 $(v_{m}^{(k)}-v_{m}^{(i)})^{2}$。

### 3.2 在大型项目中推荐

一个大型的电影流媒体网站可能有数千部电影。一个大型音乐流媒体网站可能有有数千万首歌曲可供选择。一个大型在线购物网站可能有数百万、数千万的商品。

当一个新用户进入网站，会有一个用户特征向量 $x_{u}$，而项目特征向量 $x_{m}$ 有数百万个，如果按照上一小节图 10.1 所示去计算，每一个用户都要计算百万次，那是不可能实现的。

一般来说，这种大型推荐系统的实现分为两个步骤：检索和排名。

- 检索（Retrieval）

  1. 生成大量可能的项目候选者列表

  - 比如：对于用户最近观看的 10 部电影，找出每一部对应的一个最相似的电影。
  - 比如：选择三种用户最常看的电影类型，再从这 3 个电影类型里选出 10 个评分最高的。
  - 比如：在用户所在的国家里，评分排行前 20 的电影。

  2. 获取检索步骤 1 中的所有项目，并将它们组合到一个列表中

  3. 删除一些用户已经看过的，不想再被推荐的项目

- 排名（Ranking）

  1. 将候选者列表中的数据进行神经网络的训练，并为每一个用户-电影的键值对计算预测评分

  2. 推荐给用户评分最高的一些项目

在检索过程中，选择的项目越多，推荐的效果越好，但是会降低推荐的速度。那么如何选择项目的数量呢（比如：100、500、1000），吴恩达教授的建议是进行离线实验，看看检索额外项目会产生多少更相关的推荐。

通过单独的检索步骤和排名步骤，现在的很多大型推荐系统能够提供快速和准确的结果。因为检索步骤会剪掉很多不值得做内积的项目，而排名步骤对用户实际可能会喜欢的项目能进行更仔细的预测。

### 3.3 推荐系统中的伦理

==科技就像是武器，永远都是一把双刃剑。被好人拿在手里，那就是造福社会，被坏人拿在手里，很有可能造成很多的危害。==

**正面例子**：一个旅游行业的成功之道，应该是努力把好的旅行体验给到用户，真正的去服务用户。

假设一个旅游公司，向你推荐了一些很好的旅游地点，让你和你的家人或朋友度过了一个愉快的假期。公司都是以盈利为目的的，我们可以假设这个旅游公司会拿出更高的价格去投放广告，从而获得更多的客户，赚更多的钱。

这样就构成了一个良性的循环，你服务的客户越多，业务利润就越高，你就可以为广告出更高的价格，从而获得更多的流量，更多的客户。

**反面例子**：发薪日贷款行业往往会向低收入个人收取极高的利率。这个业务中最好的方法之一是，真正有效的从客户那里榨取每一美元。

如果有一家善于开发客户的发薪日贷款公司，真正的把客户的每一分钱都压榨到位，那么这家公司的利润会更高。假设它也是从投放广告来吸引更多的客户，那么它也会拿出更多的钱去做广告宣传。

这样一来就构成了一个恶性循环。从公司盈利的角度来说，无可厚非；但是从社会从人类道德的角度而言，这是一个极坏的事情。

因此，希望各位正在学习推荐系统的各位同学，能够将自己学到的东西运用在好的事物之上。

### 3.4 TensorFlow 代码实现

![10.12 代码片段1](/machinelearning/four/10-12.png =560x)

两个小型神经网络的构建很简单，使用顺序模型组成一个密集层（dense layers）的神经网络，并且使用默认的 relu 作为激活函数。接下来要告诉 tensorflow 如何将用户和电影的特征提供给神经网络。

```py
# create the user input and point to the base network
input_user = tf.keras.layers.Input(shape=(num_user_features)) # (1)
vu = user_NN(input_user) # (2)
vu = tf.linalg.12_normalize(vu, axis=1) # (3)

# create the item input and point to the base network
input_item = tf.keras.layers.Input(shape=(num_item_features)) # (1)
vm = item_NN(input_item) # (2)
vm = tf.linalg.12_normalize(vm, axis=1) # (3)
```

- 步骤（1）表示提供用户/电影特征
- 步骤（2）表示将提供的用户/电影特征，传递给用户/电影的神经网络
- 步骤（3）表示将向量 vu/vm 标准化为长度为 1。这一步能够很大的提升性能。

```py
# (4) measure the similarity of the two vector outputs
output = tf.keras.layers.Dot(axes=1)({vu, vm})

# (5) specify the inputs and output of the model
model = Model({input_user, input_item}, output)

# (6) specify the cost function
cost_fn = tf.keras.losses.MeanSquaredError()
```

- 步骤（4）表示计算的最后一步，向量 vu 和 vm 点乘，得出预测结果。
- 步骤（5）是告诉 keras，模型的输入和输出是什么。也就是把两个小神经网络整合成一个。
- 步骤（6）是声明成本函数为均方误差成本函数。

## 4. PCA 算法

PCA 算法是一个被称为主成分分析的无监督学习算法，它是一个常用的可视化算法，数据科学家们通常会使用它来可视化数据，从而弄清楚可能发生的事情。

具体来说，如果你的数据集包含很多特征，比如 100 个、1000 个，在这么多个维度的数据上你是没有办法可视化的。PCA 可以将这些大量的特征提取并减少到 2 个或者 3 个，以便你对其绘图和可视化。

### 4.1 降低特征数量

以美国的常见汽车举例，假如我们有两个特征，车的长度和宽度（或者车的长度和轮胎直径）。

在美国，常见的私家车的宽度，基本都是固定的 1.8m 或者更窄，因为很多地方的马路限宽，同样轮胎的直径也不会有太大的差异。

因此这两个特征如果画在二维坐标系中，看起来会几乎是一条直线，因为有一个特征几乎是不变的，PCA 就可以将其忽略掉，只保留有价值的特征。

再复杂一点，比如两个特征为下图中的，车的长度和高度。这样子画出来图形，x 轴和 y 轴上都是有变化的，怎么办呢？

![10.13 PCA-降低特征数量](/machinelearning/four/10-13.png =560x)

PCA 有点像绘制线性回归方程一样，在数据的趋势方向上，绘制一条新的直线，也就是图中的 z 轴。这个 z 轴不是三维坐标系中的 z 轴，要注意一下。

我们可以概括一下，PCA 会寻找一个新的坐标轴（或者说是一个新的理解问题的角度），去表示多个有关联的特征。比如在这个例子中，size 也就是车的尺寸，车身长度、宽度、高度、轮胎直径，这些都是与车的尺寸相关。

### 4.2 PCA 算法原理

PCA 算法它是怎么知道，如何才能选择一个新轴（z 轴）去表示多个特征的共同偏好的呢？

首先，假设特征已经归一化为零均值，那么从每个特征中减去均值，或者使用特征缩放，这样范围就不会相距太远。

其次，我们需要找到一条直线，让所有数据投影过去的点，之间的距离相对较大，并且尽可能的保留更多的方差，这样可以包含更多的信息。

<div class="layout">

![10.14 PCA-算法原理1](/machinelearning/four/10-14.png =360x)

![10.15 PCA-算法原理2](/machinelearning/four/10-15.png =360x)

![10.16 PCA-算法原理3](/machinelearning/four/10-16.png =360x)

</div>

图 10.14 是原始坐标轴，它表现不错但不是最好。

图 10.15 是一个变化之后表现不好的坐标轴，因为它投影过去的点间距太近了，甚至还有重合，这样原始信息就被磨灭了很多。

图 10.16 是最佳的坐标轴变换，它也被称为主成分（轴）。

虽然 PCA 它看起来和线性回归貌似很像，但是两者之间其实完全不同。

![10.17 PCA与线性回归对比](/machinelearning/four/10-17.png =560x)

首先，线性回归是一个监督学习算法，它是有目标标签 y 的，并且算法的目的是，尽可能地让 y 与直线之间的距离最短。

而 PCA 是一个无监督学习算法，没有可对比的目标标签 y。它可以有很多的特征 x，并且它的目标是寻找一个直线，可以尽可能的保留方差，以便保留更多的有效信息。

<div class="layout">

![10.18 PCA-算法原理4](/machinelearning/four/10-18.png =360x)

![10.19 PCA-算法原理5](/machinelearning/four/10-19.png =360x)

</div>

为什么要保留有效信息，PCA 中有一个步骤叫做重建，就是尽可能的还原原本的数据信息。

图 10.18 中我们将这个（2，3）的数据变成了 3.55 的一维值的形式，如果我们在计算后没有保留原始数据（如图 10.19），通过和长度向量再次相乘可以得到（2.52，2.52）这个数据，和原本的（2，3）虽然有出入，但是也算是较好的还原了一些真实信息。

### 4.3 Scikit-learn 库实现 PCA

<div class="layout">

![10.20 PCA-代码实现1](/machinelearning/four/10-20.png =360x)

![10.21 PCA-代码实现2](/machinelearning/four/10-21.png =360x)

</div>

- ==PCA(n_components=?)== 表示保留几个主成分，1 就是降为 1 维，2 就是降为 2 维。

- ==fit(X)== 表示将 PCA 拟合到训练样本中。

- ==explained_variance_ratio\_== 表示能够捕获原始数据集中多少信息（保留多少有效信息）。我们可以看到，图 10.20 中一维坐标可以保留 99.2%的有效信息，图 10.21 中二维坐标可以保留 100%的有效信息，因为它原本就是二维的。

- ==pca_1.transform(X) 和 pca.inverse_transform()== 会将训练样本中的每一个数据投射到一个数字（一维），或新坐标轴下的坐标（二维），并且输出这个数组。
