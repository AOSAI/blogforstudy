---
title: 推荐系统基础 - 02
order: 1
author: AOSAI
date: 2023-09-28
category:
  - 推荐系统
tag:
  - 推荐系统

sticky: false # 此页面会在文章列表置顶
star: false # 此页面会出现在文章收藏中
footer: 等我攒够六便士，就去寻找月亮
copyright: AOSAI
---

## 一、推荐模型构建流程

![](/recommedation/06.png)

Data(数据) -> Features(特征) -> ML Algorithm(机器学习算法) -> Prediction Output(预测输出)

### 1.1 数据收集（数据清洗/数据处理）

- 数据来源

  - 显性数据

    - Rating 打分
    - Comments 评论/评价

  - 隐形数据

    - Order History 历史订单
    - Cart Events 加购物车
    - Page Views 页面浏览
    - Click-thru 点击
    - Search log 搜索记录

关键点：数据量/数据能否满足需求

### 1.2 特征工程

协同过滤：**用户-物品 评分矩阵**
基于内容：分词 tf-ldf word2Vec

- 从数据中筛选特征

  - 一个给定的商品，可能被拥有类似品味或者需求的用户购买
  - 使用 用户行为数据描述商品

![](/recommedation/07.png)

这个就表示，不同的用户对 17 号商品的评分，空白的就是没有点击过，没有购买过。

- 用数据表示特征

  - 将所有用户的行为合并在一起，形成一个 user-item 矩阵

![](/recommedation/08.png)

### 1.3 训练模型（选择合适的算法）

协同过滤：KNN、矩阵分解

简单的比如 余弦相似度算法，最经典的比如 协同过滤算法，具体后面会有详细的笔记。

### 1.4 评估、模型上线（产生推荐结果）

根据算法的结果进行推荐。

## 二、协同过滤推荐算法（Collaborative Filtering）

算法思想：**物以类聚，人以群分**

基础的协同过滤推荐算法基于以下假设：

- 跟你喜好**相似的人**喜欢的东西你也有可能很喜欢：基于用户的协同过滤推荐（User-based CF）
- 跟你喜欢的东西**相似的东西**你也很有可能喜欢：基于物品的协同过滤推荐（Item-based CF）

实现协同过滤有以下几个步骤：

1. 找出相似的人或物品：TOP-N 相似的人或物品

通过计算两两的相似度来进行排序，即可找出 TOP-N 的相似人或物

2. 根据相似的人或物品产生推荐结果

利用 TOP-N 结果生成初始推荐结果，然后过滤掉用户已经有过记录，或者明确表示不感兴趣的物品

![](/recommedation/09.png)

举例说明：

用户 1 和用户 2 都买了三件商品，相同的有两件，A 和 D，所以两个用户的相似度就是 2/3 \* 2/3 = 0.44。矩阵是沿主对角线对称的。

用户 1 和其他四个用户，相似度最高的两个用户分别是 3 和 2，0.76、0.44，所以初始的推荐结果就是用户 2 买过的物品和用户三买过的物品，之后再将用户 1 买过的商品过滤掉，剩下的推荐结果就是 E。

基于物品的协同过滤也是一样的流程和思想。

## 三、相似度计算（Similarity Calculation）

**数据分类：**

- 实数值（物品评分情况）
- 布尔值（用户的行为：是否点击、是否收藏等）

### 3.1 欧式距离：Euclidean distance

欧氏距离也叫欧几里得距离，是通常下采用的距离定义，它是指在 N 维空间中两个点之间的真实距离。就是两点之间直线最短的直线距离。

在二维空间下的公式：

![](/recommedation/10_ed01.png)

推广到 N 维：

![](/recommedation/10_ed02.png)

欧式距离的值是一个非负数，最大正无穷，通常计算相似度希望的结果是[-1,1]或[0,1]之间，一般可以使用如下的转化公式：

![](/recommedation/10_ed03.png)

### 3.2 余弦相似度 Cosine Similarity

在中学数学，三角形中，余弦的计算公式为：

![](/recommedation/11_2.png)

在空间向量中，余弦的计算公式为：

![](/recommedation/11_3.png)

算法理论：一个向量空间中的两个向量夹角之间的余弦值作为衡量两个个体之间差异的大小。余弦值越接近 1，夹角越趋近于 0，表明两个向量越相似。

![](/recommedation/11_1.jpg)

由图可以看出，欧氏距离是衡量两个点之间的绝对距离，而余弦相似度衡量的是空间向量的夹角，更加体现的是在方向上的差异，而不是位置距离。

欧式距离的数值受到维度的影响，余弦相似度在高维的情况下也依然保持低维完全相同时相似度为 1 等性质。

### 3.3 皮尔逊相关系数 Pearson Correlation

（1）皮尔逊相关系数的推导

在概率论中，cov 为协方差，σ 为标准差，相关系数的定义为：
![](/recommedation/12_1.png)

实际应用中，通常用 r rr 表示相关系数，假如我们有一组样本点 (x,y)，基于样本对期望、方差、协方差进行估计，计算相关系数，也就是：

![](/recommedation/12_2.png)

之所以除以 n-1 而不是除以 n，是因为我们是用样本去估计总体，除 n-1 才是统计学上的“无偏估计”，这样能使我们以较小的样本集更好的逼近总体的标准差。

将上面的这些公式，代回到定义式中，就得到了皮尔逊相关系数：

![](/recommedation/12_3.png)

（2）一些补充

相关是最常用的统计度量，用一个数来描述两个变量之间的相关联程度。相关系数的取值范围是[-1,1]，所以皮尔逊相似度的计算结果在[-1,1]之间，-1 表示负相关，一个值增大另一个值就减小；1 表示正相关，一个值增大另一个值也跟着增大；0 表示无关，一个值怎么变都对另一个值无影响。

本质也是余弦相似度，只不过先对向量做了中心化处理，向量 a，b 各自减去向量的均值之后，在计算余弦相似度。余弦相速度只考虑了方向，皮尔逊相似度还考虑了向量的长度。

如果评分数据是连续的数值，比较适合使用余弦相似度、皮尔逊相似度。

度量的是两个变量的变化趋势是否一致，不适合计算布尔值向量之间的相关度

### 3.4 杰卡德相似度 Jaccard Coefficient

给定两个集合 A,B，Jaccard 系数定义为 A 与 B 交集的大小与 A 与 B 并集的大小的比值，定义如下：

![](/recommedation/13_1.svg)

当集合 A，B 都为空时，J(A,B)定义为 1。

与 Jaccard 系数相关的指标叫做 Jaccard 距离，用于描述集合之间的不相似度。Jaccard 距离越大，样本相似度越低。公式定义如下：

![](/recommedation/13_2.svg)

其中对称差（symmetric difference）：

![](/recommedation/13_3.svg)

项目相似性度量是协同过滤系统的核心。相关研究中，基于物品协同过滤系统的相似性度量方法普遍使用余弦相似性。 然而，在许多实际应用中,评价数据稀疏度过高，物品之间通过余弦相似度计算会产生误导性结果。 将杰卡德相似性度量应用到基于物品的协同过滤系统中，并建立起相应的评价分析方法。 与传统相似性度量方法相比，杰卡德方法完善了余弦相似性只考虑用户评分而忽略了其他信息量的弊端，特别适合于应用到稀疏度过高的数据。

除了适合布尔值向量的计算，也适用于图的计算。
